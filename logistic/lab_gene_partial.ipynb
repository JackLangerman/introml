{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lab:  Logistic Regression for Gene Expression Data\n",
    "\n",
    "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In addition to the concepts in [breast cancer demo](./breast_cancer.ipynb), you will learn to:\n",
    "* Handle missing data\n",
    "* Perform multi-class logistic classification\n",
    "* Create a confusion matrix\n",
    "* Use L1-regularization for improved estimation in the case of sparse weights (Grad students only)\n",
    "\n",
    "## Background\n",
    "\n",
    "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this lab comes from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "In this data, mice were characterized by three properties:\n",
    "* Whether they had down's syndrome (trisomy) or not\n",
    "* Whether they were stimulated to learn or not\n",
    "* Whether they had a drug memantine or a saline control solution.\n",
    "\n",
    "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the Data\n",
    "\n",
    "We begin by loading the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=6, micro=1, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use the `pd.read_excel` command to read the data from \n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
    "\n",
    "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_3</th>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_4</th>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_5</th>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
       "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N   ...     pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "MouseID                                  ...                                    \n",
       "309_1     2.373744  0.232224  1.750936   ...    0.108336  0.427099   0.114783   \n",
       "309_2     2.292150  0.226972  1.596377   ...    0.104315  0.441581   0.111974   \n",
       "309_3     2.283337  0.230247  1.561316   ...    0.106219  0.435777   0.111883   \n",
       "309_4     2.152301  0.207004  1.595086   ...    0.111262  0.391691   0.130405   \n",
       "309_5     2.134014  0.192158  1.504230   ...    0.110694  0.434154   0.118481   \n",
       "\n",
       "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "MouseID                                                                       \n",
       "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "309_3    0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
       "309_4    0.147444  0.146901  1.700563   Control  Memantine       C/S  c-CS-m  \n",
       "309_5    0.140314  0.148380  1.839730   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# df = ...\n",
    "link = \"./Data_Cortex_Nuclear.xls\"\n",
    "df = pd.read_excel(link, index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This data has missing values.  The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num null df: 1396\n",
      "Mean^2 Same within: 3.73630409211e-30\n",
      "num null df: 1396\n",
      "num null df1: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# df1 = ...\n",
    "print(\"num null df:\", df.isnull().sum().sum())\n",
    "# print(\"num null df1:\", df1.isnull().sum().sum())\n",
    "df1 = df.fillna(df.mean())\n",
    "print(\"Mean^2 Same within:\",((df1.mean() - df.mean())**2).sum())\n",
    "print(\"num null df:\", df.isnull().sum().sum())\n",
    "print(\"num null df1:\", df1.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Binary Classification for Down's Syndrome\n",
    "\n",
    "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# y = ...\n",
    "\n",
    "yraw = df1['Genotype'].values\n",
    "negVal, posVal = np.unique(yraw)\n",
    "y = (yraw == posVal).astype(int)\n",
    "\n",
    "# y1 = (df1['Genotype'].values == np.unique(yraw)[1]).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As predictors, get all but the last four columns of the dataframes.  Standardize the data matrix and call the standardized matrix `Xs`.  The predictors are the expression levels of the 77 genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Xs = ...\n",
    "\n",
    "X = np.array(df1[ df1.columns[:-4] ])\n",
    "Xs = (X - np.mean(X, axis=0))/np.std(X, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a `LogisticRegression` object `logreg` and `fit` the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Measure the accuracy of the classifer.  That is, use the `logreg.predict` function to predict labels `yhat` and measure the fraction of time that the predictions match the true labels.  Below, we will properly measure the accuracy on cross-validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy proportion is 0.985.\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "yhat = logreg.predict(Xs)\n",
    "print(\"The accuracy proportion is {:.3f}.\".format(np.sum(y == yhat)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Interpreting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a stem plot of the coefficients, `W` in the logistic regression model.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niCgyTOxERJFhYiciisz/A9CKLhBrWWAeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113405a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg.intercept_\n",
    "W = np.squeeze(logreg.coef_)\n",
    "plt.stem(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.  Although, we do not discuss it in this class, there are ways to force the logistic regression to return a sparse vector `W`.  \n",
    "\n",
    "Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITSN1_N\n",
      "APP_N\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "W_sort_idx = (-abs(W)).argsort()\n",
    "print(\"\\n\".join(df1.columns[W_sort_idx[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cross Validation\n",
    "\n",
    "The above meaured the accuracy on the training data.  It is more accurate to measure the accuracy on the test data.  Perform 10-fold cross validation and measure the average precision, recall and f1-score.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the mean precision, recall and f1-score and error rate across all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre\trecall\tf_1\n",
      "0.965\t1.000\t0.982\t\n",
      "0.979\t0.940\t0.959\t\n",
      "1.000\t0.964\t0.981\t\n",
      "0.980\t0.960\t0.970\t\n",
      "1.000\t0.962\t0.981\t\n",
      "1.000\t0.961\t0.980\t\n",
      "1.000\t1.000\t1.000\t\n",
      "0.958\t0.939\t0.948\t\n",
      "0.980\t0.980\t0.980\t\n",
      "0.933\t0.955\t0.944\t\n",
      "---------------------\n",
      "0.979\t0.966\t0.973\t\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "# TODO\n",
    "nfold = 10\n",
    "\n",
    "kf = model_selection.KFold(n_splits=nfold,shuffle=True)\n",
    "\n",
    "prfa = np.zeros((nfold, 3))\n",
    "\n",
    "print(\"pre\\trecall\\tf_1\")\n",
    "for isplit, Ind in enumerate(kf.split(Xs)):\n",
    "    Itr, Its = Ind\n",
    "    X_cv_tr = Xs[Itr]\n",
    "    X_cv_ts = Xs[Its]\n",
    "    \n",
    "    y_cv_tr = y[Itr]\n",
    "    y_cv_ts = y[Its]\n",
    "    logreg.fit(X_cv_tr, y_cv_tr)\n",
    "    \n",
    "    y_hat = logreg.predict(X_cv_ts)\n",
    "\n",
    "#     print((\"{:.3f}\\t\"*3).format(\n",
    "#         *metrics.precision_recall_fscore_support(y[Its], y_hat, average='binary')) )\n",
    "    \n",
    "    prfa[isplit, :] = metrics.precision_recall_fscore_support(\n",
    "            y[Its], y_hat, average='binary')[:3]\n",
    "    \n",
    "    print((\"{:.3f}\\t\"*3).format(*prfa[isplit, :]))\n",
    "    \n",
    "print((\"-\"*21+\"\\n\"+\"{:.3f}\\t\"*3).format(*np.mean(prfa, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# y = ...\n",
    "yraw = df1['class']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(yraw)\n",
    "y = le.transform(yraw)\n",
    "\n",
    "# with unique\n",
    "y = np.zeros_like(yraw)\n",
    "yraw = df1['class']\n",
    "col_names = np.unique(yraw)\n",
    "nam2num = dict([*zip(col_names, np.arange(8))])\n",
    "\n",
    "y = np.array([*map((lambda x : nam2num[x]), yraw)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Measure the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 99.907%\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print(\"Acc: {:.3f}%\".format(100*np.mean(logreg.predict(Xs) == y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold. You can use the `confustion_matrix` method in the `sklearn` package.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will represent the fraction of samples where `yhat==j` given `ytrue==i`.  Print the confusion matrix.  You can use the command\n",
    "\n",
    "    print(np.array_str(C, precision=4, suppress_small=True))\n",
    "    \n",
    "to create a nicely formatted print.  Also print the overall mean and SE of the test error rate across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and SE of the test error are 0.987 and 0.003 respectively.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TODO\n",
    "nfold = 10\n",
    "\n",
    "kf = model_selection.KFold(n_splits=nfold,shuffle=True)\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "C = np.zeros((len(col_names),len(col_names)))\n",
    "\n",
    "for isplit, Ind in enumerate(kf.split(Xs)):\n",
    "    Itr, Its = Ind\n",
    " \n",
    "    X_cv_tr = Xs[Itr]\n",
    "    X_cv_ts = Xs[Its]\n",
    "    \n",
    "    y_cv_tr = y[Itr]\n",
    "    y_cv_ts = y[Its]\n",
    "    \n",
    "    \n",
    "    logreg.fit(X_cv_tr, y_cv_tr)\n",
    "    \n",
    "    y_hat = logreg.predict(X_cv_ts)\n",
    "    \n",
    "    C += confusion_matrix(y_hat, y_cv_ts)\n",
    "\n",
    "C = C / np.sum(C, axis=1)\n",
    "# print(np.array_str(C, precision=4, suppress_small=True))\n",
    "\n",
    "# errMean = 1-np.sum(C*np.eye(8))/8\n",
    "# errStd = np.std(C)\n",
    "\n",
    "acc = np.diagonal(C)\n",
    "mu = np.mean(acc)\n",
    "sigma = np.std(acc)\n",
    "print(\"The mean and SE of the test error are {:.3f} and {:.3f} respectively.\"\n",
    "      .format(mu, sigma/np.sqrt(nfold-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Re-run the logistic regression on the entire training data and get the weight coefficients.  This should be a 8 x 77 matrix.  Create a stem plot of the first row of this matrix to see the coefficients on each of the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHORJREFUeJzt3X+QXfV53/H3B0kIBShrrA1GK8lSEopLTEDODpiRJ2Ow\nE37EA4TaLaRNcWpGacdM406KR5QZp81MB2XoJHFjj20NprZbF9txjFCNEhmQO27dgFkQBoEsWwZs\nacFIIGQCqBKSnv5xz8LV1f255+z5+XnN3Nk9957d89177p7nnO/zfL9HEYGZmTXPCUU3wMzMiuEA\nYGbWUA4AZmYN5QBgZtZQDgBmZg3lAGBm1lAOAGZmDeUAYGbWUA4AZmYNNb/oBvSzePHiWLFiRdHN\nMDOrjIcffviFiBgfZt3UAUDSMuBLwBlAAOsj4pMd6wj4JHAF8Brw4Yh4ZNDvXrFiBVNTU2mbaGbW\nGJJ+Muy6WVwBHAb+KCIekXQq8LCkeyPiybZ1LgfOSh4XAp9JvpqZWUFS5wAi4rmZs/mI+HtgOzDR\nsdpVwJei5QFgTNKZabdtZmazl2kSWNIKYBXwYMdLE8CutuXdHB8kzMwsR5kFAEmnAH8NfCwiXk7x\ne9ZImpI0tXfv3qyaZ2ZmHTIJAJIW0Dr4fzkivtFllWlgWdvy0uS540TE+oiYjIjJ8fGhEtlmZjYL\nWVQBCfg8sD0i/qzHahuBGyV9hVby9+cR8VzabdfBhq3T3LZ5B8/uP8CSsUXcdOnZXL3KvWNmNvey\nqAJaDfwe8LikR5Pn/j2wHCAiPgtsolUCupNWGejvZ7DdytuwdZqbv/E4B14/AsD0/gPc/I3HARwE\nzGzOpQ4AEfF/AA1YJ4CPpt1W3dy2eccbB/8ZB14/wm2bdzgAmNmc81QQBXp2/4GRnjczy5IDQIGW\njC0a6Xkzsyw5ABTopkvPZtGCecc8t2jBPG669OyCWmRmTVLqyeDqbqaf/+Nff4xDR44y4SogM8uR\nA0DBrl41wZ3f+ykAX/2DiwpujZk1ibuAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwA\nzMwaygHAzKyhPBDMMuX7G5hVhwOAZcb3NzCrFncBWWb63d/AzMrHAcAy4/sbmFWLA4Blxvc3MKuW\nTAKApDsk7ZG0rcfr75X0c0mPJo9PZLFdKxff36B5NmydZvW6Laxcew+r121hw9bpoptkI8gqCfwF\n4FPAl/qs878j4gMZbc9KyPc3aBYn/asvkwAQEd+RtCKL32XV5vsbNEe/pL8DQDXkmQO4SNL3Jf2N\npF/ttZKkNZKmJE3t3bs3x+aZ2Sic9K++vALAI8DbI+I84C+BDb1WjIj1ETEZEZPj4+M5Nc/MRuWk\nf/XlEgAi4uWIeCX5fhOwQNLiPLZdNU6qWVU46V99uYwElvQ24PmICEkX0Ao8L+ax7SpxUs2qxEn/\n6sskAEi6E3gvsFjSbuCPgQUAEfFZ4IPAv5Z0GDgAXBsRkcW268RJNasaJ/2rLasqoOsGvP4pWmWi\n1oeTamaWJ48ELhEn1cwsTw4AJeKkmpnlydNBl4iTamaWJweAknFSzczy4i4gM7OGcgAwM2soBwAz\ns4ZyADAzaygHADOzhnIAMDNrKAcAM7OGcgAwM2soDwQzs8bYsHWa2zbv4Nn9B1jikfYOAGbWDL7f\nxvHcBWRmjdDvfhtN5QBgZo3g+20czwHAzBrB99s4XiYBQNIdkvZI2tbjdUn6L5J2SnpM0ruy2K6Z\n2bB8v43jZXUF8AXgsj6vXw6clTzWAJ/JaLtmZkO5etUEt15zLifOax32JsYWces15zY2AQzZ3RP4\nO5JW9FnlKuBLyY3gH5A0JunMiHgui+2bFcVlhdXi+20cK68y0AlgV9vy7uQ5BwCrLJcVWtWVLgks\naY2kKUlTe/fuLbo5Zj25rNCqLq8AMA0sa1temjx3nIhYHxGTETE5Pj6eS+PMZsNlhVZ1eQWAjcC/\nSKqB3g383P3/VnUuK7SqyyQHIOlO4L3AYkm7gT8GFgBExGeBTcAVwE7gNeD3s9iuWZFuuvTsY3IA\n4LLCQZw0L5esqoCuG/B6AB/NYltmZTFz4Pr41x/j0JGjTPiA1peT5uXjyeCs1ub6jNNlhcPrlzR3\nACiGA4DVls84y8VJ8/IpXRmoWVZcplkuTpqXjwOA1ZbPOMvFc/GUjwOA1ZbPOMvFc/GUj3MAHVym\nVh8u0ywfJ83LxQGgjZOG9eIyTbP+HADauEytfnzGadabcwBtnDQ0syZxAGjjpKGZNYkDQJthytQ2\nbJ1m9botrFx7D6vXbWHD1q6TmpqZlZ5zAG0GJQ2dJDazOnEA6NAvaegksZnVibuARuAksZnVia8A\nRrBkbBHTXQ72ThIPzwPtzMrDVwAj8Fwm6czkUKb3HyB4M4fiRLpZMRwARuC5TNLx7Jxm5eIuoBF5\nZOmxunXp9OIcig3iLsJ8ZXIFIOkySTsk7ZS0tsvrH5a0V9KjyeOGLLZrxerVpfPCKwe7ru+BdtaP\nuwjzlzoASJoHfBq4HDgHuE7SOV1W/WpEnJ88bk+7XStery6dXfu6n9E7h2L9uIswf1lcAVwA7IyI\npyLiEPAV4KoMfq+VXK+um0NHjnZ93jkU68ddhPnLIgcwAexqW94NXNhlvX8s6TeAHwL/NiJ2dVnH\nBihTH2mvstiZA3w3zqFYLy6zzl9eSeD/CdwZEQcl/QHwReCSbitKWgOsAVi+fHlOzSuv9gP+aYsW\n8Oqhw7x+JIDip6LodcOVJWMn5d4Wqz7fwCd/WXQBTQPL2paXJs+9ISJejIiZzODtwK/3+mURsT4i\nJiNicnx8PIPmVVdnUmz/gdffOPjPKLKPtFeXzuJTFr6xjifPs2G5izB/WVwBPAScJWklrQP/tcDv\ntq8g6cyIeC5ZvBLYnsF2a69bUqybIvtIu3XpzCz3mjxvydhJxwSJOilTF10V5d1F2Lm/Ln7HON/+\nwd7G7L/UASAiDku6EdgMzAPuiIgnJP0JMBURG4F/I+lK4DCwD/hw2u3OVpX+QYc9sJe1j7RflVAd\nA4Bni62Wbvvrvz/w0zdeb8L+y2QcQERsioh/GBG/HBH/KXnuE8nBn4i4OSJ+NSLOi4iLI+IHWWx3\nVFWrMx7mwF7mPtJRq4SqzmWM1TLMFXbd91+jpoKo2j9ot7r5BSeI+ScIKH8faa8A1q9KqMpcxlgt\nw+6XOu+/Rk0FUbV/0F43qKlKGWXTqoSaUMY4ytQfZddrf3Vbr67qeSrWQxWnIrh61QSrlo9x4crT\n+e7aS0p7tt/NMFVCVdOvqqnuI51Hnfqj7Lrtr0512n/dNOoKoIg642GqDOqsX5VQ1Qyqahp0S9Gq\nKyKpP5dFG93218XvGOdrD+2u5f7rplEBIO9/0GGrDOpcFlknwxwAyz7SOU3ZY95J/Tyqqrrtrx89\n/8oxy3XWqAAA+f6DDltlUNeyyLqpelVT2rLH2Uz9kYbvwT33GpUDyNuwyeWqHECarupVTWnLHnvl\nOJadPjc5tKoVbVRRNT65FTVscrkqB5Cmy/sAmLW0ZY95J/WrWLRRNT7yzKFhqwyqcgBpuqpXNQ17\n4Oy3Xp5VaVlUVXkuqv4cAOZQtwPGP3/38soeQKzaZblVK3tMOzlc3cpW50LjksB5G6bKoKplkVa8\nUap6qlj2mKZoo2lzUc2GA0DDVWlyPBt8f4hBVT1NKnusetVWHtwF1GBVmxyv6Ya5P0SnMs91Ndeq\nXrWVB18BNJjrrMuv/Yz/BIkj0f+A302asskqz/0zF3NRDbpirtoVtQNAw7R/QHsdSlxnXQ6dA7dm\nc/CH2ZdNVv2GPoMmUxzVoJHJVbwfhK+FGqSzC6EX11mXw7B3hOsnTVVPvyRqVWRZtTVoOvmqTTcP\nvgJolGEOKGUqA2y6Ya7EFpwgAjh8NDKv6skiiVrlLqROg0YmV3HksgNAgwz6IJaxDLDJBs1X3+v+\nEFlV9aSd+6fqXUidBt3voYr3g8ikC0jSZZJ2SNopaW2X1xdK+mry+oOSVmSxXRtNv6qIKg5sykOR\nI0l7jYT95fGTCx2JO+zI9Tp0IbUbNDK5iveDSB0AJM0DPg1cDpwDXCfpnI7VPgK8FBG/Avw58Kdp\nt5uXOg0lr/pcNnkreiRp0VNPpN1+3erwB41MTjtyuQiKWVYWvPELpIuA/xARlybLNwNExK1t62xO\n1vk7SfOBnwHjMWDjk5OTMTU1NXKb7r7h3zH27NOseOvJADzz4qsAbyw/+dzLAJxz5j/o+/ovnrqQ\np154laNH32zmCSeIhfNPYMG8E3r+/KDtZb08aPvtyy+8cpAf732ViGDh/NbBf8/fH5z178u7/Vm0\nb9iff+nV1zl4+PiciSROPWl+bn9f1u9v1uv3+vlh37+07Sv6/cvq89a+vH/JSq66/T8f994NQ9LD\nETE5zLpZ5AAmgF1ty7uBC3utExGHJf0ceCvwQucvk7QGWAOwfPnyWTVo36sHOfHQmx+81w4d+yH8\nhROPPQvu9fqufQeOOfgDHD0aHDp8lNMWLej584O2l/XyoO23Ly8+ZSGvHDwMvPmBm1kGeOGVgzz/\n8kEigpdefZ1lpy+a879vlPbPZnm22+t28AKIiGN+51z/fVm/v1mv3+vnl52+qOsJ1KknzT/mSjRt\n++by/ev2/zDq+zWb/b/v1XyuMrO4AvggcFlE3JAs/x5wYUTc2LbOtmSd3cnyj5N1jgsA7WZzBbBh\n6/TIN1H/p5/7u66vr1x7T9dySQFPr/vtnj/f6/fNlUHbH7Y9nUk7eHPgzOJTFs7Z3zdq+9P+vcP+\n/O6XDnRN6k2MLeK7ay/J7e9Lo9v/w6AuibTbb//5YQZGjbq9vN6/Xv8Pnd06WX3esmp/3lcA08Cy\ntuWlyXPd1tmddAGdBryYwbaPMbPDZvoY01YdVCGrv2HrNFt/up9DR46yet2WVAknT551rCLuIZ2l\nXv8PkN/ApKtXTZS6D7yfJoyUz6IK6CHgLEkrJZ0IXAts7FhnI3B98v0HgS2D+v9nI+uqg7Jn9Xv9\ng882SVm3pF1aM0m9ibFFiGok9dpVcWBSmVSxrn9Uqa8Akj79G4HNwDzgjoh4QtKfAFMRsRH4PPDf\nJO0E9tEKEpnL+gA2849e1rk9sj5jz/uer1nI8gqomyqfwTbhADaXqtADkFYmA8EiYhOwqeO5T7R9\n//+AD2WxrX7m4gBW5gNA1gFvLibPmktZd/nVTRMOYHOp6l2Awyjvqd0sNK3OPevpbnt1eZT1YFq3\ngUZZK3sXJrx5Bffg0/tKN84miy7AMv99ULOpIHp12dT1jltzccbe7YqnrO+fcxb9lb0LswxJ6kHS\n9ABU4Qq1VgEAqnUAS6tpAa9TFXMWeStzF2bdq2yGydHNdQ5rkNoFgKaZ64BX9Ae0n6rlLOxYdU9S\nD7pCLcMVgk+VrKesy0yzVrWchR2rVw6rLknqQTm6MuSwGh8Ayp6kKVIRH9BR98fVqyb47tpLeHrd\nb89qdkzv/+JUIUmdxqCilDLksBodAHqd4fog0JL3B7Tb/rjpr77Pwz95aU4O0GW/wqm7qg+0G2TQ\nFWoZblrf6BxA3ZNQaeWdZO22P15vm0gs6z5ST31RvDInqbPQL0dXhhxWo68A6p6ESivvcRXDvO9Z\ndkGV4RLcmqsMOaxGXwF4pGR/eZeZDroF4oysDtAuI7WiFV223uhPet2TUFlIm2QdRbf90U1WB+im\njRw369ToAFD3JFTVdO6PsUULWDBPx6yT5QG6DJfgZkVqdBcQ1D8JVTWd+6PbDUWyvETutr3OgW/+\nfFhdNT4AWLnl2UdahblpzLLU6C4gs3a+gUr1eCBfOg4AZgmXBVeLB/Kl5wBglqj73DR1U4a5dKou\nVQCQdLqkeyX9KPn6lh7rHZH0aPLovF+wVUidL7ldFlwtHsiXXtorgLXA/RFxFnB/stzNgYg4P3lc\nmXKbVpC6z53ksuBqKcNcOlWX9p26Cvhi8v0XgatT/j4rsSYkSfMc+FZHeV4hVnEgX9muoNMGgDMi\n4rnk+58BZ/RY7yRJU5IekOQgUVFOklo/eV8hVm0gXxmvoAeOA5B0H/C2Li/d0r4QESEpuqwH8PaI\nmJb0S8AWSY9HxI97bG8NsAZg+fLlg5pnOfLcSdkr8x3XRlXE7LpFz6UzijLOPjzwCiAi3h8R7+zy\nuBt4XtKZAMnXPT1+x3Ty9SngfwGr+mxvfURMRsTk+Pj4LP4kmytOkmarbmWMvkLsr4zvT9ouoI3A\n9cn31wN3d64g6S2SFibfLwZWA0+m3K4VwEnSbNWtjLEMZbRl62NvV4b3p1PaqSDWAV+T9BHgJ8A/\nAZA0CfyriLgB+EfA5yQdpRVw1kWEA0BFee6k7NStjLHXDU7yukIs+1QeRb8/3aQKABHxIvC+Ls9P\nATck3/9f4Nw02zHLSt6TvfXr46/b/Qh63T8ir4NvGfvY2xX9/nTjyeCsMfI+Q+y1vZlbWpbhloBZ\nK/IKsYx97J3KdgVdzVMNs1nIexzDoD7+qpUxll0Z+9jLzgHAGiPvM8R+ffwzSUrAA88y4iq10TkA\nWGPkfYY46PeWYSBQnbhKbXTOAVhj5F2F0W17ncqUpKyDsvWxl52vAKwx8j5D7NxeL2VKUlqx8h7H\n4CsAa5S8zxDbt7d63RZPpZFSne/ZXMQ4htpfAZR5ZKA1i5OU6ZRxMrUsFTHbbq0DQN0/MFYtw3RB\n+YSlt7pPR17EOIZadwGVfWSgNU+/LqiyT2VQtCoM9EqjiNl2a30FUPcPjNVL3c9w06r7QK8iughr\nHQDq/oGxevEJS391z6EUMY6h1l1AZZx9z9KpcxWIb7jTXxknU8ta3lVqtQ4ATfjANEnd+8h9wjKY\nB3plq9YBAPyBqZO6J/V9wmJ5q30AsPpoQh+5T1gsT7VOAlu9OKlvli0HAKuMuleBWPVUfeBeqgAg\n6UOSnpB0NLkPcK/1LpO0Q9JOSWvTbNOay9P9WpnUYaaBtDmAbcA1wOd6rSBpHvBp4DeB3cBDkjb6\nxvA2G+4jt7KoQ1FC2pvCbweQ+k12ywXAzoh4Kln3K8BVgAOAmVVWHYoS8sgBTAC72pZ3J8+ZmVVW\nHYoSBgYASfdJ2tblcdVcNEjSGklTkqb27t07F5tolKonqczKqg5FCQO7gCLi/Sm3MQ0sa1temjzX\na3vrgfUAk5OTkXLbjVaFkbN1ntrB6q0OA/fyGAj2EHCWpJW0DvzXAr+bw3Ybr+xJqioEKLN+ql6U\nkLYM9Hck7QYuAu6RtDl5fomkTQARcRi4EdgMbAe+FhFPpGu2DaPsSSpPf2xWrLRVQHcBd3V5/lng\nirblTcCmNNuy0ZV9dsmyByizuvNI4Bore5KqDlUUZlXmAFBjZR85W/YAZVZ3ng205sqcpKpDFYVZ\nlTkAWKGyDlAuKzUbnruArDbqMDmXWZ4cAKw2XFZqNhoHAKsNl5WajcYBwGrDZaVmo3EAsNpwWanZ\naFwFZLXhslKz0TgAWK2UedyDWdm4C8jMrKEcAMzMGsoBwMysoRwAzMwaygHAzKyhHADMzBoq7S0h\nPyTpCUlHJU32We8ZSY9LelTSVJptls3M7JMPPr2P1eu2eOIxM6uMtFcA24BrgO8Mse7FEXF+RPQM\nFFXTa/bJF145WHDLzGbHJzTNkioARMT2iGjsVIu9Zp/ctc+Tj1n1eDrt5skrBxDAtyQ9LGlNTtuc\nc71mmZz5BzKrEk+n3TwDp4KQdB/wti4v3RIRdw+5nfdExLSkXwTulfSDiOjabZQEiDUAy5cvH/LX\nF2PJ2CKmuwSBE+c5t27V4+m0m2fgkSoi3h8R7+zyGPbgT0RMJ1/3AHcBF/RZd31ETEbE5Pj4+LCb\nKESv2SeXne7ph616PJ1288z5qaqkkyWdOvM98Fu0kseVd/WqCW695lwmxhYhYGJsEbdecy6LT1lY\ndNPMRubptJsn1Wygkn4H+EtgHLhH0qMRcamkJcDtEXEFcAZwl6SZ7f2PiPjblO0ujW6zT975vZ8W\n1Bqz2fN02s2TKgBExF20unQ6n38WuCL5/ingvDTbMbN8eDrtZnG20sysoRwAzMwaygEgYx5JaWZV\n4QCQIY+kNLMqcQDIkEdSmlmVOABkyCMpzaxKHAAy5JGUZlYlDgAZ8khKM6uSVAPB7FgeSWlmVeIA\nkLGiR1LOlKEeOnKU1eu2OACZWU/uAqoRl6Ga2SgcAGrEZahmNgoHgBpxGaqZjcIBoEZchmpmo3AA\nqBGXoZrZKFwFVCMuQzWzUTgA1EzRZahmVh3uAjIza6hUAUDSbZJ+IOkxSXdJGuux3mWSdkjaKWlt\nmm2amVk20l4B3Au8MyJ+DfghcHPnCpLmAZ8GLgfOAa6TdE7K7ZqZWUqpAkBEfCsiDieLDwBLu6x2\nAbAzIp6KiEPAV4Cr0mzXzMzSyzIH8C+Bv+ny/ASwq215d/KcmZkVaGAVkKT7gLd1eemWiLg7WecW\n4DDw5bQNkrQGWJMsviJptvMYLAZeSNueOeT2peP2peP2pVPm9r192BUHBoCIeH+/1yV9GPgA8L6I\niC6rTAPL2paXJs/12t56YP2gdg0iaSoiJtP+nrni9qXj9qXj9qVT9vYNK20V0GXAx4ErI+K1Hqs9\nBJwlaaWkE4FrgY1ptmtmZumlzQF8CjgVuFfSo5I+CyBpiaRNAEmS+EZgM7Ad+FpEPJFyu2ZmllKq\nkcAR8Ss9nn8WuKJteROwKc22ZiF1N9Icc/vScfvScfvSKXv7hqLu3fZmZlZ3ngrCzKyhahcAyjjt\nhKQ7JO2RtK3tudMl3SvpR8nXtxTUtmWSvi3pSUlPSPrDkrXvJEnfk/T9pH3/MXl+paQHk/381aTA\noDCS5knaKumbJW3fM5IeT3J1U8lzpdjHSVvGJH09mVpmu6SLytI+SWcn79vM42VJHytL+9KoVQAo\n8bQTXwAu63huLXB/RJwF3J8sF+Ew8EcRcQ7wbuCjyXtWlvYdBC6JiPOA84HLJL0b+FPgz5M81EvA\nRwpq34w/pFXkMKNs7QO4OCLObytfLMs+Bvgk8LcR8Q7gPFrvZSnaFxE7kvftfODXgdeAu8rSvlQi\nojYP4CJgc9vyzcDNRbcracsKYFvb8g7gzOT7M4EdRbcxacvdwG+WsX3ALwCPABfSGoQzv9t+L6Bd\nS2kdAC4BvgmoTO1L2vAMsLjjuVLsY+A04GmSnGTZ2tfRpt8CvlvW9o36qNUVANWaduKMiHgu+f5n\nwBlFNgZA0gpgFfAgJWpf0r3yKLCH1gSEPwb2x5vzUBW9n/+C1niYo8nyWylX+wAC+Jakh5PR9lCe\nfbwS2Av816Qb7XZJJ5eofe2uBe5Mvi9j+0ZStwBQSdE6hSi0HEvSKcBfAx+LiJfbXyu6fRFxJFqX\n30tpTS74jqLa0knSB4A9EfFw0W0Z4D0R8S5a3aMflfQb7S8WvI/nA+8CPhMRq4BX6ehOKfozCJDk\nca4E/qrztTK0bzbqFgBGmnaiYM9LOhMg+bqnqIZIWkDr4P/liPhG2do3IyL2A9+m1aUyJmlmHEuR\n+3k1cKWkZ2jNdHsJrf7ssrQPgIiYTr7uodV/fQHl2ce7gd0R8WCy/HVaAaEs7ZtxOfBIRDyfLJet\nfSOrWwCo0rQTG4Hrk++vp9X3njtJAj4PbI+IP2t7qSztG1dyoyFJi2jlJ7bTCgQfLLp9EXFzRCyN\niBW0Pm9bIuKflaV9AJJOlnTqzPe0+rG3UZJ9HBE/A3ZJOjt56n3Ak5SkfW2u483uHyhf+0ZXdBIi\n6wetEcg/pNVPfEvR7UnadCfwHPA6rbOdj9DqJ74f+BFwH3B6QW17D61L18eAR5PHFSVq368BW5P2\nbQM+kTz/S8D3gJ20LskXlmA/vxf4Ztnal7Tl+8njiZn/i7Ls46Qt5wNTyX7eALylZO07GXgROK3t\nudK0b7YPjwQ2M2uounUBmZnZkBwAzMwaygHAzKyhHADMzBrKAcDMrKEcAMzMGsoBwMysoRwAzMwa\n6v8Dr9gatFf0aGYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114140438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg.fit(Xs, y)\n",
    "W = logreg.coef_\n",
    "plt.stem(W[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L1-Regularization\n",
    "\n",
    "Graduate students only complete this section.\n",
    "\n",
    "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, we would expect that the weight coefficients in the logistic regression model should be sparse.  That is, they should be zero on any gene that plays no role in the particular attribute of interest.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term.  Read the `sklearn` [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the `LogisticRegression` class to see how to set the l1-penalty and the inverse regularization strength, `C`.\n",
    "\n",
    "Using the model selection strategies from the [prostate cancer analysis demo](../model_sel/prostate.ipynb), use K-fold cross validation to select an appropriate inverse regularization strength.  \n",
    "* Use 10-fold cross validation \n",
    "* You should select around 20 values of `C`.  It is up to you find a good range.\n",
    "* Make appropriate plots and print out to display your results\n",
    "* How does the accuracy compare to the accuracy achieved without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1153b1940>]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYa+JHXI/wdBdqa8Nu6q5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11441f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "print(logreg)\n",
    "Cs = np.logspace(-5, -1, 30)\n",
    "plt.plot(Cs, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n",
      "(20, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "nfold = 10\n",
    "\n",
    "kf = model_selection.KFold(n_splits=nfold,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "Cs = np.logspace(-1, 2, 20)\n",
    "acc = np.zeros((nfold, len(Cs)))\n",
    "\n",
    "for isplit, Ind in enumerate(kf.split(Xs)):\n",
    "    Itr, Its = Ind\n",
    " \n",
    "    X_cv_tr = Xs[Itr]\n",
    "    X_cv_ts = Xs[Its]\n",
    "    \n",
    "    y_cv_tr = y[Itr]\n",
    "    y_cv_ts = y[Its]\n",
    "    \n",
    "    for ic, c in enumerate(Cs):\n",
    "        logreg = linear_model.LogisticRegression(C=c, penalty='l1')\n",
    "        logreg.fit(X_cv_tr, y_cv_tr)\n",
    "\n",
    "        y_hat = logreg.predict(X_cv_ts)\n",
    "        \n",
    "        acc[isplit, ic] = np.mean(y_hat == y_cv_ts)\n",
    "#         print(np.mean(y_hat == y_cv_ts))\n",
    "\n",
    "    print(np.array([*zip(Cs, acc[isplit, :])]).shape)\n",
    "#     plt.figure()\n",
    "#     plt.plot([*zip(Cs, acc)])\n",
    "    \n",
    "#     plt.plot(Cs, acc, label=isplit)\n",
    "#     plt.legend()\n",
    "accMean = np.mean(acc, axis=0)\n",
    "acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.83298071e+01,   7.84759970e+00,   3.35981829e+00,\n",
       "         1.00000000e+02,   6.15848211e-01,   4.28133240e+01,\n",
       "         1.43844989e+00,   2.63665090e-01,   1.12883789e-01,\n",
       "         4.83293024e-02])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158262b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accMean = np.mean(acc, axis=0)\n",
    "print(acc.shape)\n",
    "print(accMean.shape)\n",
    "plt.plot(Cs, accMean)\n",
    "srtIdx = (-accMean).argsort()\n",
    "accMean[srtIdx]\n",
    "Cs[srtIdx[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the optimal `C`, fit the model on the entire training data with l1 regularization. Find the resulting weight matrix, `W_l1`.  Plot the first row of this weight matrix and compare it to the first row of the weight matrix without the regularization.  You should see that, with l1-regularization, the weight matrix is much more sparse and hence the roles of particular genes are more clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
